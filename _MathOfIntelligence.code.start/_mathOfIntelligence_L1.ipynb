{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Gradient descent (optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lec 1\n",
    "#The optimal values of m and b can be actually calculated with way less effort than doing a linear regression. \n",
    "#this is just to demonstrate gradient descent\n",
    "\n",
    "from numpy import *\n",
    "#import os\n",
    "#os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y = mx + b\n",
    "# m is slope, b is y-intercept\n",
    "def compute_error_for_line_given_points(b, m, points):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        totalError += (y - (m * x + b)) ** 2 # from eqn.\n",
    "    return totalError / float(len(points))\n",
    "\n",
    "\n",
    "def step_gradient(b_current, m_current, points, learningRate):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current)) # partial derivative eqn1.\n",
    "        m_gradient += -(2/N) * x * (y - ((m_current * x) + b_current)) # partial derivative eqn2\n",
    "    new_b = b_current - (learningRate * b_gradient) # weight1 update\n",
    "    new_m = m_current - (learningRate * m_gradient) # weight2 update\n",
    "    return [new_b, new_m]\n",
    "\n",
    "def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    for i in range(num_iterations):\n",
    "        b, m = step_gradient(b, m, array(points), learning_rate)\n",
    "    return [b, m]\n",
    "\n",
    "\n",
    "def run():\n",
    "    points = genfromtxt(\"data.csv\", delimiter=\",\")\n",
    "    learning_rate = 0.0001\n",
    "    initial_b = 0 # initial y-intercept guess\n",
    "    initial_m = 0 # initial slope guess\n",
    "    num_iterations = 1000\n",
    "    print(\"Starting gradient descent at b = {0}, m = {1}, error = {2}\".format(initial_b, initial_m, compute_error_for_line_given_points(initial_b, initial_m, points)))\n",
    "    print(\"Running...\")\n",
    "    [b, m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)\n",
    "    print(\"After {0} iterations b = {1}, m = {2}, error = {3}\".format(num_iterations, b, m, compute_error_for_line_given_points(b, m, points)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = genfromtxt(\"data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32.50234527  31.70700585]\n",
      " [ 53.42680403  68.77759598]\n",
      " [ 61.53035803  62.5623823 ]\n",
      " [ 47.47563963  71.54663223]\n",
      " [ 59.81320787  87.23092513]\n",
      " [ 55.14218841  78.21151827]\n",
      " [ 52.21179669  79.64197305]\n",
      " [ 39.29956669  59.17148932]\n",
      " [ 48.10504169  75.3312423 ]\n",
      " [ 52.55001444  71.30087989]\n",
      " [ 45.41973014  55.16567715]\n",
      " [ 54.35163488  82.47884676]\n",
      " [ 44.1640495   62.00892325]\n",
      " [ 58.16847072  75.39287043]\n",
      " [ 56.72720806  81.43619216]\n",
      " [ 48.95588857  60.72360244]\n",
      " [ 44.68719623  82.89250373]\n",
      " [ 60.29732685  97.37989686]\n",
      " [ 45.61864377  48.84715332]\n",
      " [ 38.81681754  56.87721319]\n",
      " [ 66.18981661  83.87856466]\n",
      " [ 65.41605175 118.5912173 ]\n",
      " [ 47.48120861  57.25181946]\n",
      " [ 41.57564262  51.39174408]\n",
      " [ 51.84518691  75.38065167]\n",
      " [ 59.37082201  74.76556403]\n",
      " [ 57.31000344  95.45505292]\n",
      " [ 63.61556125  95.22936602]\n",
      " [ 46.73761941  79.05240617]\n",
      " [ 50.55676015  83.43207142]\n",
      " [ 52.22399609  63.35879032]\n",
      " [ 35.56783005  41.4128853 ]\n",
      " [ 42.43647694  76.61734128]\n",
      " [ 58.16454011  96.76956643]\n",
      " [ 57.50444762  74.08413012]\n",
      " [ 45.44053073  66.58814441]\n",
      " [ 61.89622268  77.76848242]\n",
      " [ 33.09383174  50.71958891]\n",
      " [ 36.43600951  62.12457082]\n",
      " [ 37.67565486  60.81024665]\n",
      " [ 44.55560838  52.68298337]\n",
      " [ 43.31828263  58.56982472]\n",
      " [ 50.07314563  82.90598149]\n",
      " [ 43.87061265  61.4247098 ]\n",
      " [ 62.99748075 115.2441528 ]\n",
      " [ 32.66904376  45.57058882]\n",
      " [ 40.16689901  54.0840548 ]\n",
      " [ 53.57507753  87.99445276]\n",
      " [ 33.86421497  52.72549438]\n",
      " [ 64.70713867  93.57611869]\n",
      " [ 38.11982403  80.16627545]\n",
      " [ 44.50253806  65.10171157]\n",
      " [ 40.59953838  65.56230126]\n",
      " [ 41.72067636  65.28088692]\n",
      " [ 51.08863468  73.43464155]\n",
      " [ 55.0780959   71.13972786]\n",
      " [ 41.37772653  79.10282968]\n",
      " [ 62.49469743  86.52053844]\n",
      " [ 49.20388754  84.74269781]\n",
      " [ 41.10268519  59.35885025]\n",
      " [ 41.18201611  61.68403752]\n",
      " [ 50.18638949  69.84760416]\n",
      " [ 52.37844622  86.09829121]\n",
      " [ 50.13548549  59.10883927]\n",
      " [ 33.64470601  69.89968164]\n",
      " [ 39.55790122  44.86249071]\n",
      " [ 56.13038882  85.49806778]\n",
      " [ 57.36205213  95.53668685]\n",
      " [ 60.26921439  70.25193442]\n",
      " [ 35.67809389  52.72173496]\n",
      " [ 31.588117    50.39267014]\n",
      " [ 53.66093226  63.64239878]\n",
      " [ 46.68222865  72.24725107]\n",
      " [ 43.10782022  57.81251298]\n",
      " [ 70.34607562 104.25710159]\n",
      " [ 44.49285588  86.64202032]\n",
      " [ 57.5045333   91.486778  ]\n",
      " [ 36.93007661  55.23166089]\n",
      " [ 55.80573336  79.55043668]\n",
      " [ 38.95476907  44.84712424]\n",
      " [ 56.9012147   80.20752314]\n",
      " [ 56.86890066  83.14274979]\n",
      " [ 34.3331247   55.72348926]\n",
      " [ 59.04974121  77.63418251]\n",
      " [ 57.78822399  99.05141484]\n",
      " [ 54.28232871  79.12064627]\n",
      " [ 51.0887199   69.58889785]\n",
      " [ 50.28283635  69.51050331]\n",
      " [ 44.21174175  73.68756432]\n",
      " [ 38.00548801  61.36690454]\n",
      " [ 32.94047994  67.17065577]\n",
      " [ 53.69163957  85.66820315]\n",
      " [ 68.76573427 114.85387123]\n",
      " [ 46.2309665   90.12357207]\n",
      " [ 68.31936082  97.91982104]\n",
      " [ 50.03017434  81.53699078]\n",
      " [ 49.23976534  72.11183247]\n",
      " [ 50.03957594  85.23200734]\n",
      " [ 48.14985889  66.22495789]\n",
      " [ 25.12848465  53.45439421]]\n"
     ]
    }
   ],
   "source": [
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0, m = 0, error = 5565.107834483211\n",
      "Running...\n",
      "After 1000 iterations b = 0.08893651993741346, m = 1.4777440851894448, error = 112.61481011613473\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.70700585,  68.77759598,  62.5623823 ,  71.54663223,\n",
       "        87.23092513,  78.21151827,  79.64197305,  59.17148932,\n",
       "        75.3312423 ,  71.30087989,  55.16567715,  82.47884676,\n",
       "        62.00892325,  75.39287043,  81.43619216,  60.72360244,\n",
       "        82.89250373,  97.37989686,  48.84715332,  56.87721319,\n",
       "        83.87856466, 118.5912173 ,  57.25181946,  51.39174408,\n",
       "        75.38065167,  74.76556403,  95.45505292,  95.22936602,\n",
       "        79.05240617,  83.43207142,  63.35879032,  41.4128853 ,\n",
       "        76.61734128,  96.76956643,  74.08413012,  66.58814441,\n",
       "        77.76848242,  50.71958891,  62.12457082,  60.81024665,\n",
       "        52.68298337,  58.56982472,  82.90598149,  61.4247098 ,\n",
       "       115.2441528 ,  45.57058882,  54.0840548 ,  87.99445276,\n",
       "        52.72549438,  93.57611869,  80.16627545,  65.10171157,\n",
       "        65.56230126,  65.28088692,  73.43464155,  71.13972786,\n",
       "        79.10282968,  86.52053844,  84.74269781,  59.35885025,\n",
       "        61.68403752,  69.84760416,  86.09829121,  59.10883927,\n",
       "        69.89968164,  44.86249071,  85.49806778,  95.53668685,\n",
       "        70.25193442,  52.72173496,  50.39267014,  63.64239878,\n",
       "        72.24725107,  57.81251298, 104.25710159,  86.64202032,\n",
       "        91.486778  ,  55.23166089,  79.55043668,  44.84712424,\n",
       "        80.20752314,  83.14274979,  55.72348926,  77.63418251,\n",
       "        99.05141484,  79.12064627,  69.58889785,  69.51050331,\n",
       "        73.68756432,  61.36690454,  67.17065577,  85.66820315,\n",
       "       114.85387123,  90.12357207,  97.91982104,  81.53699078,\n",
       "        72.11183247,  85.23200734,  66.22495789,  53.45439421])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Include necessary modules and declaration of x and y variables through which we are going to define the gradient descent optimization\n",
    "#x = tf.Variable(2, name = 'x', dtype = tf.float32)\n",
    "#log_x = tf.log(x)\n",
    "#log_x_squared = tf.square(log_x)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(log_x_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "starting at x: 2.0 log(x)^2: 0.480453\n",
      "step 0 x: 1.6534264 log(x)^2: 0.25285786\n",
      "step 1 x: 1.3493005 log(x)^2: 0.08975197\n",
      "step 2 x: 1.1272696 log(x)^2: 0.014351669\n",
      "step 3 x: 1.0209966 log(x)^2: 0.0004317744\n",
      "step 4 x: 1.0006447 log(x)^2: 4.1534943e-07\n",
      "step 5 x: 1.0000006 log(x)^2: 3.5527118e-13\n",
      "step 6 x: 1.0 log(x)^2: 0.0\n",
      "step 7 x: 1.0 log(x)^2: 0.0\n",
      "step 8 x: 1.0 log(x)^2: 0.0\n",
      "step 9 x: 1.0 log(x)^2: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Initialize the necessary variables and call the optimizers for defining and calling it with respective function\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "def optimize():\n",
    "   with tf.Session() as session:\n",
    "      session.run(init)\n",
    "      print(\"starting at\", \"x:\", session.run(x), \"log(x)^2:\", session.run(log_x_squared))\n",
    "      \n",
    "      for step in range(10):\n",
    "         session.run(train)\n",
    "         print(\"step\", step, \"x:\", session.run(x), \"log(x)^2:\", session.run(log_x_squared))\n",
    "optimize()\n",
    "\n",
    "#cite: https://www.tutorialspoint.com/tensorflow/tensorflow_gradient_descent_optimization.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
