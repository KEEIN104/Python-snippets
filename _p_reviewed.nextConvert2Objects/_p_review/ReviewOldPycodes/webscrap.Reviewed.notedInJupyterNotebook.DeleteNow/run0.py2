'''
if __name__=='__main__':
	import sys
	sys.path.append('/home/kishore/p/webscrap/')

	from webscrap1 import *
	from function2 import *

	
'''
#download_function.py2
import urllib2

def download(url, user_agent = 'orek', num_retries=2):
   print 'Downloading:',url
   headers = {'User_agent':user_agent}
   request = urllib2.Request(url,headers = headers)
   
   try:
      html = urllib2.urlopen(request).read()
	
   except urllib2.URLError as e:
      print 'Download error:',e.reason
      html = None
		
      if num_retries > 0:
         if hasattr(e,'code') and 500 <= e.code < 600:
            #recursively retry 5xx http errors
            return download(url, num_retries-1)
   return html


#crawl_sitemap.py2

def crawl_sitemap(url):
   import re
	#download the sitemap file
   sitemap = download(url)
	#extract the sitemap links
   links =  re.findall('<loc>(.*?)</loc>', sitemap)
	#download each link
   for link in links:
		html = download(link)
		# scrape html here
		#...

crawl_sitemap('http://example.webscraping.com/sitemap.xml')
